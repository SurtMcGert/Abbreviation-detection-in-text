# NLP Coursework

This is a repo for the NLP Coursework at the University of Surrey.

## Dataset

This work was done using the PLOD dataset found at https://github.com/surrey-nlp/PLOD-AbbreviationDetection

## Branches

Each member of the group has their own branch to work on and experiment on. Each member's experiments are detailed below.

### Harry

1. HMM vs BERT
2. Loss function comparison
3. added data samples
4. hyperparameter tuning

### Chris

### Adam
1. BERT vs RoBERTa vs XLNet
2. No pre-processing vs lemmatization vs stemming
3. Pre-trained model vs training from scratch vs LoRA fine-tuning
4. Hyperparameter tuning

### Paula
