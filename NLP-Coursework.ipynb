{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Seed and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "import gensim.downloader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchtext\n",
    "import tensorflow as tf\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "\n",
    "SEED = 1234\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "WORD2VEC_VECTORS = gensim.downloader.load(\"word2vec-google-news-300\")\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "\n",
    "print(\"PyTorch Version: \", torch.__version__)\n",
    "print(\"torchtext Version: \", torchtext.__version__)\n",
    "print(f\"Using {'GPU' if str(DEVICE) == 'cuda' else 'CPU'}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset load and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"surrey-nlp/PLOD-CW\")\n",
    "\n",
    "training_set = dataset[\"train\"]\n",
    "print(len(training_set))\n",
    "validation_set = dataset[\"validation\"]\n",
    "print(len(validation_set))\n",
    "testing_set = dataset[\"test\"]\n",
    "print(len(testing_set))\n",
    "\n",
    "X_raw = training_set[\"tokens\"]\n",
    "y_raw = training_set[\"ner_tags\"]\n",
    "\n",
    "X = [word for sublist in X_raw for word in sublist]\n",
    "y = [label for sublist in y_raw for label in sublist]\n",
    "\n",
    "X_validation_raw = [word for sublist in validation_set[\"tokens\"] for word in sublist]\n",
    "y_validation_raw  = [label for sublist in validation_set[\"ner_tags\"] for label in sublist]\n",
    "\n",
    "X_test_raw = [word for sublist in testing_set[\"tokens\"] for word in sublist]\n",
    "y_test_tags = [label for sublist in testing_set[\"ner_tags\"] for label in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_dataset(dataset, folder, name):\n",
    "    # Count the number of instances of each tag\n",
    "    ner_tags = [tag for record in dataset[\"ner_tags\"] for tag in record]\n",
    "    ner_tag_freq = Counter(ner_tags)\n",
    "\n",
    "    # Create pie chart for ner tag frequency\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.pie(ner_tag_freq.values(), labels=ner_tag_freq.keys(), autopct=\"%1.1f%%\")\n",
    "    plt.title(\"NER Distribution\")\n",
    "    plt.savefig(f\"{folder}/{name}-ner-tag-distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    \n",
    "    # Analysis of which pos tag each ner tag belongs to\n",
    "    pos_tags = [tag for record in dataset[\"pos_tags\"] for tag in record]\n",
    "    tags_combined = zip(ner_tags, pos_tags)\n",
    "    tags_freq = Counter(tags_combined)\n",
    "\n",
    "    tags_freq_BAC = {}\n",
    "    for item, counter in tags_freq.items():\n",
    "        if item[0] == \"B-LF\" or item[0] == \"I-LF\":\n",
    "            tags_freq_BAC[item[1]] = counter\n",
    "    tags_freq_BAC_filtered = filter_by_threshold(tags_freq_BAC)\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.pie(tags_freq_BAC_filtered.values(), labels=tags_freq_BAC_filtered.keys(), autopct=\"%1.1f%%\")\n",
    "    plt.title(\"POS Tag Distribution for LF NER\")\n",
    "    plt.savefig(f\"{folder}/{name}-LF-POS.png\")\n",
    "    plt.close()\n",
    "\n",
    "    tags_freq_BOC = {}\n",
    "    for item, counter in tags_freq.items():\n",
    "        if item[0] == \"B-O\":\n",
    "            tags_freq_BOC[item[1]] = counter\n",
    "\n",
    "    tags_freq_BOC_filtered = OrderedDict(sorted(tags_freq_BOC.items(), key=lambda x: x[1], reverse=True))\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.bar(tags_freq_BOC_filtered.keys(), tags_freq_BOC_filtered.values())\n",
    "    plt.xticks(rotation=65)\n",
    "    plt.title(\"Non-Abbreviation POS distribution\")\n",
    "    plt.savefig(f\"{folder}/{name}-non-abbrv.png\")\n",
    "    plt.close()\n",
    "    \n",
    "def filter_by_threshold(dictionary, threshold_proportion=0.05):\n",
    "    threshold = round((sum(dictionary.values()) * threshold_proportion), 0)\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "\n",
    "    dict_filtered = {\"other\" : 0}\n",
    "    for item, counter in dictionary.items():\n",
    "        if counter >= threshold:\n",
    "            dict_filtered[item] = counter\n",
    "        else:\n",
    "            dict_filtered[\"other\"] += counter\n",
    "    \n",
    "    return dict_filtered\n",
    "        \n",
    "    \n",
    "analyse_dataset(training_set, \"training-plots\", \"training\")\n",
    "analyse_dataset(validation_set, \"validation-plots\", \"validation\")\n",
    "analyse_dataset(testing_set, \"testing-plots\", \"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"B-O\", \"B-AC\", \"B-LF\", \"I-LF\"]\n",
    "labels_vocab = {\n",
    "    \"B-O\": 0,\n",
    "    \"B-AC\": 1,\n",
    "    \"B-LF\": 2,\n",
    "    \"I-LF\": 3,\n",
    "}\n",
    "print(\"Converting labels\")\n",
    "integer_labels_2d = np.array([labels_vocab[label] for label in y])\n",
    "y_validation_integers = np.array([labels_vocab[label] for label in y_validation_raw])\n",
    "y_test_integers = np.array([labels_vocab[label] for label in y_test_tags])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(list, labels):\n",
    "    toReturn = []\n",
    "    toReturnLabels = []\n",
    "\n",
    "    for i, word in enumerate(list):\n",
    "        if (word not in stopwords):\n",
    "            toReturn.append(word)\n",
    "            toReturnLabels.append(labels[i])\n",
    "\n",
    "    return toReturn, toReturnLabels\n",
    "\n",
    "def stem(list):\n",
    "    ps = PorterStemmer()\n",
    "    return [ps.stem(word) for word in list]\n",
    "\n",
    "def lower_case(list):\n",
    "    return [word.lower() for word in list]\n",
    "\n",
    "def lemmatize(list):\n",
    "    l = WordNetLemmatizer()\n",
    "    return [l.lemmatize(word) for word in list]\n",
    "        \n",
    "exp1 = {}\n",
    "\n",
    "# Remove stop word\n",
    "exp1[\"rsw\"], y_labels_processed = remove_stop_words(X, integer_labels_2d)\n",
    "# Stem\n",
    "exp1[\"stem\"] = stem(X)\n",
    "# Stem, lower case\n",
    "exp1[\"stem-lc\"] = stem(lower_case(X))\n",
    "# Remove stop word, stem, lower case\n",
    "exp1[\"rsw-stem-lc\"] = lower_case(stem(exp1[\"rsw\"]))\n",
    "# Remove stop word, lemmatize\n",
    "exp1[\"rsw-lemmatize\"] = lemmatize(exp1[\"rsw\"])\n",
    "# Remove stop word, lower case, lemmatize\n",
    "exp1[\"rsw-lc-lemmatize\"] = lemmatize(lower_case(exp1[\"rsw\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under/Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def get_sample(samplerType, X_in, y_in):\n",
    "    if samplerType==\"over\":\n",
    "        sampler = RandomOverSampler()\n",
    "    elif samplerType==\"under\":\n",
    "        sampler = RandomUnderSampler()\n",
    "    else:\n",
    "        return None\n",
    "    X_sampled_2d, y_sampled_labels = sampler.fit_resample(np.array(X_in).reshape(-1, 1), np.array(y_in))\n",
    "\n",
    "    if (type(X_sampled_2d[0])) == np.ndarray:\n",
    "        X_sampled_2d = [item for sublist in X_sampled_2d for item in sublist]\n",
    "    if (type(y_sampled_labels[0])) == np.ndarray:\n",
    "        y_sampled_labels = [labels_vocab[label] for label in y_sampled_labels]\n",
    "\n",
    "    return X_sampled_2d, y_sampled_labels\n",
    "\n",
    "X_undersampled, y_undersampled = get_sample(\"under\", X, y)\n",
    "print(np.shape(X_undersampled))\n",
    "X_oversampled, y_oversampled = get_sample(\"over\", X, y)\n",
    "print(np.shape(X_oversampled))\n",
    "\n",
    "X_validation_undersampled, y_validation_undersampled = get_sample(\"under\", X_validation_raw, y_validation_raw)\n",
    "X_validation_oversampled, y_validation_oversampled = get_sample(\"over\", X_validation_raw, y_validation_raw)\n",
    "\n",
    "def analyse_sampled_set(set, name):\n",
    "    # Create pie chart for ner tag frequency\n",
    "    ner_tag_freq = Counter(set)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.pie(ner_tag_freq.values(), labels=ner_tag_freq.keys(), autopct=\"%1.1f%%\")\n",
    "    plt.title(f\"NER Distribution ({ner_tag_freq.total()})\")\n",
    "    plt.savefig(f\"sampled/{name}-ner-tag-distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "analyse_sampled_set(y_undersampled, \"training_undersampled\")\n",
    "analyse_sampled_set(y_oversampled, \"training_oversampled\")\n",
    "\n",
    "analyse_sampled_set(y_validation_undersampled, \"validation_undersampled\")\n",
    "analyse_sampled_set(y_validation_oversampled, \"validation_oversampled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_word2vec(text):\n",
    "    vectors = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            vector = WORD2VEC_VECTORS[word]\n",
    "            vectors.append(vector)\n",
    "        except:\n",
    "            vectors.append(np.zeros(300,))\n",
    "    return vectors\n",
    "\n",
    "X_training = {}\n",
    "X_training[\"word2vec\"] = text_to_word2vec(X)\n",
    "\n",
    "\n",
    "X_validation = {}\n",
    "X_validation[\"word2vec\"] = text_to_word2vec(X_validation_raw)\n",
    "\n",
    "\n",
    "X_test_word2vec = [word for sublist in testing_set[\"tokens\"] for word in sublist]\n",
    "X_testing = {}\n",
    "X_testing[\"word2vec\"] = text_to_word2vec(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Training and Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1_vec = {}\n",
    "for exp in exp1:\n",
    "    exp1_vec[exp] = text_to_word2vec(exp1[exp])\n",
    "    \n",
    "models = []\n",
    "for i, test in enumerate(exp1_vec):\n",
    "    prediction = None\n",
    "    models.append(SGDClassifier(class_weight=\"balanced\"))\n",
    "    if \"rsw\" in test:\n",
    "        models[i].fit(exp1_vec[test], y_labels_processed)\n",
    "    else:\n",
    "        models[i].fit(exp1_vec[test], integer_labels_2d)\n",
    "\n",
    "    prediction = models[i].predict(X_validation[\"word2vec\"])\n",
    "    print(f\"============ {test} ============\\n{metrics.classification_report(y_validation_integers, prediction)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under/Oversampling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled_vec = text_to_word2vec(X_undersampled)\n",
    "X_oversampled_vec = text_to_word2vec(X_oversampled)\n",
    "\n",
    "X_validation_undersampled_vec = text_to_word2vec(X_validation_undersampled) \n",
    "X_validation_oversampled_vec = text_to_word2vec(X_validation_oversampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_undersampled = SGDClassifier()\n",
    "model_undersampled.fit(X_undersampled_vec, y_undersampled)\n",
    "model_undersampled_predictions = model_undersampled.predict(X_validation_undersampled_vec)\n",
    "print(f\"============ Undersampled ============\\n{metrics.classification_report(y_validation_undersampled, model_undersampled_predictions)}\")\n",
    "\n",
    "model_oversampled = SGDClassifier()\n",
    "model_oversampled.fit(X_oversampled_vec, y_oversampled)\n",
    "model_oversampled_predictions = model_oversampled.predict(X_validation_oversampled_vec)\n",
    "print(f\"============ Oversampled ============\\n{metrics.classification_report(y_validation_oversampled, model_oversampled_predictions)}\")\n",
    "\n",
    "model_balanced = SGDClassifier(class_weight=\"balanced\")\n",
    "model_balanced.fit(X_training[\"word2vec\"], integer_labels_2d)\n",
    "model_balanced_predictions = model_balanced.predict(X_validation[\"word2vec\"])\n",
    "print(f\"============ \\\"balanced\\\" ============\\n{metrics.classification_report(y_validation_integers, model_balanced_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = exp1[\"rsw-lemmatize\"]\n",
    "X_validation_preprocessed_raw, y_validation_processed = remove_stop_words(lemmatize(X_validation_raw), y_validation_raw)\n",
    "y_validation_processed = [labels_vocab[label] for label in y_validation_processed]\n",
    "\n",
    "X_training_preprocessed = {}\n",
    "X_training_preprocessed[\"word2vec\"] = text_to_word2vec(X_processed)\n",
    "\n",
    "X_validation_preprocessed = {}\n",
    "X_validation_preprocessed[\"word2vec\"] = text_to_word2vec(X_validation_preprocessed_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "X_training_preprocessed[\"tf-idf\"] = tfidf.fit_transform(X_processed)\n",
    "X_validation_preprocessed[\"tf-idf\"] = tfidf.transform(X_validation_preprocessed_raw)\n",
    "X_testing[\"tf-idf\"] = tfidf.transform(X_test_raw)\n",
    "\n",
    "svm_tf_idf = SGDClassifier(class_weight=\"balanced\")\n",
    "svm_tf_idf.fit(X_training_preprocessed[\"tf-idf\"], y_labels_processed)\n",
    "\n",
    "svm_tf_idf_predictions = svm_tf_idf.predict(X_validation_preprocessed[\"tf-idf\"])\n",
    "print(metrics.classification_report(y_validation_processed, svm_tf_idf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "glove_model = api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_glove(text):\n",
    "    vectors = []\n",
    "    \n",
    "    for word in text:\n",
    "        try:\n",
    "            vector = glove_model[word]\n",
    "            vectors.append(vector)\n",
    "        except:\n",
    "            vectors.append(np.zeros(300,))\n",
    "\n",
    "    return vectors\n",
    "\n",
    "X_training_preprocessed[\"GloVe\"] = text_to_glove(X_processed)\n",
    "X_validation_preprocessed[\"GloVe\"] = text_to_glove(X_validation_preprocessed_raw)\n",
    "X_testing[\"GloVe\"] = text_to_glove(X_test_raw)\n",
    "\n",
    "# With preprocessing\n",
    "print(\"Converting labels\")\n",
    "integer_labels_2d = np.array([labels_vocab[label] for label in y])\n",
    "\n",
    "svm_glove = SGDClassifier(class_weight=\"balanced\")\n",
    "svm_glove.fit(X_training_preprocessed[\"GloVe\"], y_labels_processed)\n",
    "\n",
    "svm_glove_predictions = svm_glove.predict(X_validation_preprocessed[\"GloVe\"])\n",
    "print(metrics.classification_report(y_validation_processed, svm_glove_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Fitting SVM model\")\n",
    "svm_word2vec = SGDClassifier(class_weight=\"balanced\")\n",
    "svm_word2vec.fit(X_training_preprocessed[\"word2vec\"], y_labels_processed)\n",
    "\n",
    "svm_word2vec_predictions = svm_word2vec.predict(X_validation_preprocessed[\"word2vec\"])\n",
    "print(metrics.classification_report(y_validation_processed, svm_word2vec_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SET_X = X_training_preprocessed[\"word2vec\"]\n",
    "TRAINING_SET_y = y_labels_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_squared_hinge = SGDClassifier(loss=\"squared_hinge\", class_weight=\"balanced\")\n",
    "svm_squared_hinge.fit(TRAINING_SET_X, TRAINING_SET_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_perceptron = SGDClassifier(loss=\"perceptron\", class_weight=\"balanced\")\n",
    "svm_perceptron.fit(TRAINING_SET_X, TRAINING_SET_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_modified_huber = SGDClassifier(loss=\"modified_huber\", class_weight=\"balanced\")\n",
    "svm_modified_huber.fit(TRAINING_SET_X, TRAINING_SET_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_epsilon_insensitive = SGDClassifier(loss=\"epsilon_insensitive\", class_weight=\"balanced\")\n",
    "svm_epsilon_insensitive.fit(TRAINING_SET_X, TRAINING_SET_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_squared_epsilon_insensitive = SGDClassifier(loss=\"squared_epsilon_insensitive\", class_weight=\"balanced\")\n",
    "svm_squared_epsilon_insensitive.fit(TRAINING_SET_X, TRAINING_SET_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SET_X = X_validation_preprocessed[\"word2vec\"]\n",
    "VALIDATION_SET_y = y_validation_processed\n",
    "\n",
    "y_pred = svm_word2vec.predict(VALIDATION_SET_X)\n",
    "print(f\"\\n====== Hinge loss (default) ======\\n{metrics.classification_report(VALIDATION_SET_y, y_pred)}\")\n",
    "\n",
    "svm_squared_hinge_predictions = svm_squared_hinge.predict(VALIDATION_SET_X)\n",
    "print(f\"\\n====== Squared Hinge loss ======\\n{metrics.classification_report(VALIDATION_SET_y, svm_squared_hinge_predictions)}\")\n",
    "\n",
    "svm_perceptron_predictions = svm_perceptron.predict(VALIDATION_SET_X)\n",
    "print(f\"\\n====== Perceptron ======\\n{metrics.classification_report(VALIDATION_SET_y, svm_perceptron_predictions)}\")\n",
    "\n",
    "svm_modified_huber_predictions = svm_modified_huber.predict(VALIDATION_SET_X)\n",
    "print(f\"\\n====== Modified Huber ======\\n{metrics.classification_report(VALIDATION_SET_y, svm_modified_huber_predictions)}\")\n",
    "\n",
    "svm_epsilon_insensitive_predictions = svm_epsilon_insensitive.predict(VALIDATION_SET_X)\n",
    "print(f\"\\n====== Epsilon Insensitive ======\\n{metrics.classification_report(VALIDATION_SET_y, svm_epsilon_insensitive_predictions)}\")\n",
    "\n",
    "svm_squared_epsilon_insensitive_predictions = svm_squared_epsilon_insensitive.predict(VALIDATION_SET_X)\n",
    "print(f\"\\n====== Squared Epsilon Insensitive ======\\n{metrics.classification_report(VALIDATION_SET_y, svm_squared_epsilon_insensitive_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "def objective(trial):\n",
    "    alpha = trial.suggest_float('alpha', 1e-5, 1e5, log=True)\n",
    "    eta0 = trial.suggest_float('eta0', 1e-4, 1e4, log=True)\n",
    "    \n",
    "    svm_model = SGDClassifier(loss=\"log_loss\", alpha=alpha, learning_rate=\"adaptive\", eta0=eta0)\n",
    "\n",
    "    svm_model.fit(X_training_preprocessed[\"word2vec\"], y_labels_processed)\n",
    "\n",
    "    optim_pred = svm_model.predict(X_validation_preprocessed[\"word2vec\"])\n",
    "    optim_f1 = metrics.f1_score(y_validation_processed, optim_pred, average=\"macro\")\n",
    "\n",
    "    return optim_f1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "svm_optimised = SGDClassifier(loss=\"log_loss\", alpha=best_params[\"alpha\"], learning_rate=\"adaptive\", eta0=best_params[\"eta0\"])\n",
    "svm_optimised.fit(X_training_preprocessed[\"word2vec\"], y_labels_processed)\n",
    "\n",
    "svm_optimized_predictions = svm_optimised.predict(X_validation_preprocessed[\"word2vec\"])\n",
    "print(metrics.classification_report(y_validation_processed, svm_optimized_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_validation_processed, svm_optimized_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = study.get_trials()\n",
    "print(trials[0].report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = SGDClassifier(loss=\"squared_epsilon_insensitive\", alpha=best_params[\"alpha\"], learning_rate=\"adaptive\", eta0=best_params[\"eta0\"])\n",
    "\n",
    "X_final, y_final = get_sample(\"over\", exp1[\"rsw-lemmatize\"], y_labels_processed)\n",
    "X_final_vec = text_to_word2vec(X_final)\n",
    "\n",
    "print(np.shape(X_final_vec))\n",
    "model_final.fit(X_final_vec, y_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vec = text_to_word2vec(X_test_raw)\n",
    "model_final_predictions = model_final.predict(X_test_vec)\n",
    "print(metrics.classification_report(y_test_integers, model_final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
